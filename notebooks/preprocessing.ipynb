{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c4d896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d9d43a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>35.8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8000</td>\n",
       "      <td>2.83000</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>3104.2375</td>\n",
       "      <td>14.60000</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>3104.2375</td>\n",
       "      <td>30.63625</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>159.3625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3000</td>\n",
       "      <td>2.75000</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_period  koi_duration  koi_depth  koi_prad  koi_teq  koi_insol  \\\n",
       "0    9.488036       2.95750   615.8000   2.26000    793.0      93.59   \n",
       "1   54.418383       4.50700   874.8000   2.83000    443.0       9.11   \n",
       "2   19.899140       1.78220  3104.2375  14.60000    638.0      39.30   \n",
       "3    1.736952       2.40641  3104.2375  30.63625   1395.0     891.96   \n",
       "4    2.525592       1.65450   603.3000   2.75000   1406.0     926.16   \n",
       "\n",
       "   koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0        35.8000              0              0              0              0   \n",
       "1        25.8000              0              0              0              0   \n",
       "2        76.3000              0              0              0              0   \n",
       "3       159.3625              0              1              0              0   \n",
       "4        40.9000              0              0              0              0   \n",
       "\n",
       "   koi_steff  koi_slogg  koi_srad  koi_kepmag koi_disposition  \n",
       "0     5455.0      4.467     0.927      15.347       CONFIRMED  \n",
       "1     5455.0      4.467     0.927      15.347       CONFIRMED  \n",
       "2     5853.0      4.544     0.868      15.436       CANDIDATE  \n",
       "3     5805.0      4.564     0.791      15.597  FALSE POSITIVE  \n",
       "4     6031.0      4.438     1.046      15.509       CONFIRMED  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('data/df_KOI_capped.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd51a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['koi_disposition'] = data['koi_disposition'].map({\n",
    "    'FALSE POSITIVE': 0,\n",
    "    'CANDIDATE': 1,\n",
    "    'CONFIRMED': 2\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43ae844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('koi_disposition', axis=1)\n",
    "y=data['koi_disposition']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b483339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.00000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.209430</td>\n",
       "      <td>4.841954</td>\n",
       "      <td>983.51153</td>\n",
       "      <td>8.798627</td>\n",
       "      <td>1026.311637</td>\n",
       "      <td>541.574355</td>\n",
       "      <td>51.898302</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.232748</td>\n",
       "      <td>0.197512</td>\n",
       "      <td>0.120033</td>\n",
       "      <td>5700.771644</td>\n",
       "      <td>4.358883</td>\n",
       "      <td>1.129717</td>\n",
       "      <td>14.276929</td>\n",
       "      <td>0.781159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.539130</td>\n",
       "      <td>3.252243</td>\n",
       "      <td>1135.99106</td>\n",
       "      <td>11.429235</td>\n",
       "      <td>627.129609</td>\n",
       "      <td>733.548542</td>\n",
       "      <td>55.983546</td>\n",
       "      <td>4.767290</td>\n",
       "      <td>0.422605</td>\n",
       "      <td>0.398142</td>\n",
       "      <td>0.325018</td>\n",
       "      <td>647.930473</td>\n",
       "      <td>0.262971</td>\n",
       "      <td>0.434656</td>\n",
       "      <td>1.336585</td>\n",
       "      <td>0.863287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>3.773375</td>\n",
       "      <td>0.119875</td>\n",
       "      <td>10.617000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.733684</td>\n",
       "      <td>2.437750</td>\n",
       "      <td>166.80000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>22.160000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5333.000000</td>\n",
       "      <td>4.232750</td>\n",
       "      <td>0.835750</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.752831</td>\n",
       "      <td>3.792600</td>\n",
       "      <td>421.10000</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>141.600000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.520000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.715178</td>\n",
       "      <td>6.276500</td>\n",
       "      <td>1341.77500</td>\n",
       "      <td>13.112500</td>\n",
       "      <td>1352.500000</td>\n",
       "      <td>806.797500</td>\n",
       "      <td>71.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6099.000000</td>\n",
       "      <td>4.539000</td>\n",
       "      <td>1.313000</td>\n",
       "      <td>15.322000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.687418</td>\n",
       "      <td>12.034625</td>\n",
       "      <td>3104.23750</td>\n",
       "      <td>30.636250</td>\n",
       "      <td>2551.750000</td>\n",
       "      <td>1983.753750</td>\n",
       "      <td>159.362500</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7248.000000</td>\n",
       "      <td>4.998375</td>\n",
       "      <td>2.028875</td>\n",
       "      <td>18.145000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        koi_period  koi_duration   koi_depth     koi_prad      koi_teq  \\\n",
       "count  9564.000000   9564.000000  9564.00000  9564.000000  9564.000000   \n",
       "mean     28.209430      4.841954   983.51153     8.798627  1026.311637   \n",
       "std      35.539130      3.252243  1135.99106    11.429235   627.129609   \n",
       "min       0.241843      0.052000     0.00000     0.080000    25.000000   \n",
       "25%       2.733684      2.437750   166.80000     1.430000   553.000000   \n",
       "50%       9.752831      3.792600   421.10000     2.390000   878.000000   \n",
       "75%      40.715178      6.276500  1341.77500    13.112500  1352.500000   \n",
       "max      97.687418     12.034625  3104.23750    30.636250  2551.750000   \n",
       "\n",
       "         koi_insol  koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "count  9564.000000    9564.000000    9564.000000    9564.000000   \n",
       "mean    541.574355      51.898302       0.208595       0.232748   \n",
       "std     733.548542      55.983546       4.767290       0.422605   \n",
       "min       0.000000       0.000000       0.000000       0.000000   \n",
       "25%      22.160000      12.300000       0.000000       0.000000   \n",
       "50%     141.600000      23.000000       0.000000       0.000000   \n",
       "75%     806.797500      71.125000       0.000000       0.000000   \n",
       "max    1983.753750     159.362500     465.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_co  koi_fpflag_ec    koi_steff    koi_slogg     koi_srad  \\\n",
       "count    9564.000000    9564.000000  9564.000000  9564.000000  9564.000000   \n",
       "mean        0.197512       0.120033  5700.771644     4.358883     1.129717   \n",
       "std         0.398142       0.325018   647.930473     0.262971     0.434656   \n",
       "min         0.000000       0.000000  4184.000000     3.773375     0.119875   \n",
       "25%         0.000000       0.000000  5333.000000     4.232750     0.835750   \n",
       "50%         0.000000       0.000000  5767.000000     4.438000     1.000000   \n",
       "75%         0.000000       0.000000  6099.000000     4.539000     1.313000   \n",
       "max         1.000000       1.000000  7248.000000     4.998375     2.028875   \n",
       "\n",
       "        koi_kepmag  koi_disposition  \n",
       "count  9564.000000      9564.000000  \n",
       "mean     14.276929         0.781159  \n",
       "std       1.336585         0.863287  \n",
       "min      10.617000         0.000000  \n",
       "25%      13.440000         0.000000  \n",
       "50%      14.520000         0.000000  \n",
       "75%      15.322000         2.000000  \n",
       "max      18.145000         2.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f60b1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff608d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 3. Transform test data (DON'T fit again!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "779f604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f354b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training Random Forest...\n",
      "‚úÖ Random Forest Results:\n",
      "Accuracy:  0.9111\n",
      "Precision: 0.8857\n",
      "Recall:    0.8832\n",
      "F1-Score:  0.8842\n",
      "Best Params: {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "[[921  15   3]\n",
      " [ 10 315  80]\n",
      " [  5  57 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       939\n",
      "           1       0.81      0.78      0.80       405\n",
      "           2       0.86      0.89      0.87       569\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.89      0.88      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "üîß Training Decision Tree...\n",
      "‚úÖ Decision Tree Results:\n",
      "Accuracy:  0.8913\n",
      "Precision: 0.8614\n",
      "Recall:    0.8536\n",
      "F1-Score:  0.8560\n",
      "Best Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}\n",
      "[[920  13   6]\n",
      " [ 10 283 112]\n",
      " [  5  62 502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       939\n",
      "           1       0.79      0.70      0.74       405\n",
      "           2       0.81      0.88      0.84       569\n",
      "\n",
      "    accuracy                           0.89      1913\n",
      "   macro avg       0.86      0.85      0.86      1913\n",
      "weighted avg       0.89      0.89      0.89      1913\n",
      "\n",
      "\n",
      "üîß Training Gradient Boosting...\n",
      "‚úÖ Gradient Boosting Results:\n",
      "Accuracy:  0.9101\n",
      "Precision: 0.8842\n",
      "Recall:    0.8811\n",
      "F1-Score:  0.8823\n",
      "Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}\n",
      "[[922  15   2]\n",
      " [  9 312  84]\n",
      " [  5  57 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.81      0.77      0.79       405\n",
      "           2       0.85      0.89      0.87       569\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.88      0.88      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "üîß Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Logistic Regression Results:\n",
      "Accuracy:  0.8055\n",
      "Precision: 0.7720\n",
      "Recall:    0.7381\n",
      "F1-Score:  0.7373\n",
      "Best Params: {'C': 1.0, 'solver': 'liblinear'}\n",
      "[[884   9  46]\n",
      " [ 41 166 198]\n",
      " [ 20  58 491]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       939\n",
      "           1       0.71      0.41      0.52       405\n",
      "           2       0.67      0.86      0.75       569\n",
      "\n",
      "    accuracy                           0.81      1913\n",
      "   macro avg       0.77      0.74      0.74      1913\n",
      "weighted avg       0.81      0.81      0.79      1913\n",
      "\n",
      "\n",
      "üîß Training AdaBoost...\n",
      "‚úÖ AdaBoost Results:\n",
      "Accuracy:  0.8840\n",
      "Precision: 0.8538\n",
      "Recall:    0.8425\n",
      "F1-Score:  0.8451\n",
      "Best Params: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "[[918  11  10]\n",
      " [  2 269 134]\n",
      " [  5  60 504]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.79      0.66      0.72       405\n",
      "           2       0.78      0.89      0.83       569\n",
      "\n",
      "    accuracy                           0.88      1913\n",
      "   macro avg       0.85      0.84      0.85      1913\n",
      "weighted avg       0.89      0.88      0.88      1913\n",
      "\n",
      "\n",
      "üèÜ Best Model: RandomForestClassifier with Accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# === Define Models & Hyperparameters ===\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 20],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 5]\n",
    "    },\n",
    "\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 1.0]\n",
    "    },\n",
    "\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# === Train and Evaluate ===\n",
    "best_model = None\n",
    "best_score = 0\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîß Training {name}...\")\n",
    "    grid = GridSearchCV(model, params[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"‚úÖ {name} Results:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    \n",
    "    # Assuming y_true and y_pred are available\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "\n",
    "    model_scores[name] = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'best_params': grid.best_params_\n",
    "    }\n",
    "\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "# === Save Best Model ===\n",
    "print(f\"\\nüèÜ Best Model: {type(best_model).__name__} with Accuracy: {best_score:.4f}\")\n",
    "pickle.dump(best_model, open(\"best_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef69a070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 2, 1, 0], shape=(1913,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085f684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda0573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e28e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
